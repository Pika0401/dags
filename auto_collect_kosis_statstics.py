"""
@title í†µê³„ì²­ í†µê³„í‘œ OpenAPI ìë™ ìˆ˜ì§‘ ver 2
@author í˜„ë™ë¹ˆ (bwg)
@date 2025-04-30
@description í†µê³„ì²­ KOSIS(OpenAPI) í†µê³„í‘œ ë°ì´í„°ë¥¼ ë§¤ì¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ì—¬ Oracle DBì— ì €ì¥í•˜ëŠ” ë³‘ë ¬ ìˆ˜ì§‘ í”„ë¡œê·¸ë¨

------------------------------------------------------------

â–  ëª©ì 
- í†µê³„ì²­(KOSIS) OpenAPIë¥¼ í†µí•´ ë§¤ì¼ ìë™ìœ¼ë¡œ ìµœì‹  í†µê³„í‘œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘
- ìˆ˜ì§‘ ê²°ê³¼ë¥¼ Oracle DBì— ì €ì¥í•˜ì—¬ í›„ì† ì²˜ë¦¬ ë° í†µê³„ ë¶„ì„ ê°€ëŠ¥
- ìˆ˜ì§‘ ì™„ë£Œ ì—¬ë¶€ë¥¼ CD_COLLECT_KOSIS_OPENAPI_YN í…Œì´ë¸”ì— ê¸°ë¡í•˜ì—¬ ì¶”ì  ê°€ëŠ¥
- ë³‘ë ¬ ì²˜ë¦¬ë¡œ ëŒ€ëŸ‰ í†µê³„í‘œì˜ ë¹ ë¥¸ ìˆ˜ì§‘ êµ¬í˜„

------------------------------------------------------------
â–  ì£¼ìš” íë¦„
1. kosis_config.iniì—ì„œ ì‹¤í–‰ì¼ì, DB ì„¤ì •, ë¼ì´ì„ ìŠ¤ í‚¤, ë¡œê·¸ ê²½ë¡œ ë“±ì„ ë¡œë“œ
2. ì„¤ì •ëœ ì‹¤í–‰ì¼(execute_date)ì„ ê¸°ì¤€ìœ¼ë¡œ, ì´ì „ Nì¼ê°„ ì—…ë°ì´íŠ¸ëœ í†µê³„í‘œë¥¼ í•„í„°ë§
3. Oracleì—ì„œ ìˆ˜ì§‘ ëŒ€ìƒ í†µê³„í‘œ ëª©ë¡ ì¡°íšŒ (CD_KOSIS_REQ_MPP_P)
   - kosis_config.iniì— ì§€ì •ëœ TBL_IDë§Œ í•„í„°ë§ ê°€ëŠ¥ (ì„ íƒì )
   - ìˆ˜ì§‘ ëŒ€ìƒ ëª©ë¡ info ë¡œê·¸ ì¶œë ¥ ë° ì¤‘ë³µ TBL_ID ìë™ ê²½ê³ 
4. ê° í†µê³„í‘œë³„ 'ìë£Œê°±ì‹ ì¼' ë©”íƒ€ì •ë³´ ìš”ì²­ (ì¬ì‹œë„ ë° ë°±ì˜¤í”„ í¬í•¨)
5. ìë£Œê°±ì‹ ì¼ì´ ì§€ì • ë²”ìœ„ ë‚´ì¸ ê²½ìš°ë§Œ ìˆ˜ì§‘ ëŒ€ìƒ ì„ ì •
6. URLì„ ìƒì„±í•˜ê³  ì¤‘ë³µ ì œê±° í›„, ThreadPoolExecutorë¥¼ ì‚¬ìš©í•´ ë³‘ë ¬ ìš”ì²­ ìˆ˜í–‰
   - ìš”ì²­ ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 10íšŒ ì¬ì‹œë„, timeout=(120ì´ˆ, 300ì´ˆ)
7. ì‘ë‹µ ë°ì´í„°ë¥¼ ì»¬ëŸ¼ ì •ê·œí™”, ê²°ì¸¡ê°’/ë¹„ì •ìƒê°’ ì œê±° í›„ Oracle DBì— ì²­í¬ ë‹¨ìœ„ë¡œ ì €ì¥
8. í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì „ COMPLETE_YN = 'N', ì‹¤í–‰ í›„ 'Y'ë¡œ ë³€ê²½
   - ìƒíƒœ ê´€ë¦¬ í…Œì´ë¸”: CD_COLLECT_KOSIS_OPENAPI_YN
9. ì „ì²´ ìˆ˜ì§‘ ê±´ìˆ˜ ë° ì„±ê³µë¥  ë¡œê·¸ ì¶œë ¥

------------------------------------------------------------
â–  ì‹¤í–‰ í™˜ê²½
- Python 3.7 ì´ìƒ
- Oracle Instant Client ì„¤ì¹˜ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”
- ì˜ì¡´ íŒ¨í‚¤ì§€: oracledb, pandas, numpy, requests, configparser ë“±

------------------------------------------------------------
â–  êµ¬ì„± íŒŒì¼
- kosis_config/kosis_config.ini : ì‹¤í–‰ì¼ì, DB ì—°ê²° ì •ë³´, ë¼ì´ì„ ìŠ¤ í‚¤, ë¡œê·¸ ê²½ë¡œ, í•„í„° TBL_ID ì„¤ì •
  - ì˜ˆì‹œ:
    execute_date = 2025-05-21
    days_back = 6
    max_workers = 15
    tbl_id = DT_1EA1201, DT_1F02005
- kosis_reader.py : í†µê³„ì²­ OpenAPI ë©”íƒ€ ìš”ì²­ ì „ìš© í´ë˜ìŠ¤
- kosis_logs/ : ë‚ ì§œë³„ info/error ë¡œê·¸ ìë™ ìƒì„± (TimedRotatingFileHandler)

------------------------------------------------------------
â–  ì£¼ìš” í•¨ìˆ˜
- run_kosis_process_logging() : ìˆ˜ì§‘, ì •ì œ, ì €ì¥ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
- fetch_url() : ë‹¨ì¼ URLì— ëŒ€í•œ API ìš”ì²­ ë° pandas DataFrame ë³€í™˜
- upsert_complete_flag() : ìƒíƒœ ê´€ë¦¬ í…Œì´ë¸”ì— COMPLETE_YN í”Œë˜ê·¸ ì‚½ì… ë˜ëŠ” ê°±ì‹ 
- setup_logger() : ì¼ìë³„ ë¡œê·¸ í•¸ë“¤ëŸ¬ ìƒì„± ë° ë¡œê·¸ ë ˆë²¨ ì„¤ì •

------------------------------------------------------------
â–  ë¡œê¹… ë° ë””ë²„ê¹…
- ìˆ˜ì§‘ ëŒ€ìƒ í†µê³„í‘œ ìˆ˜ ë° TBL_ID ëª©ë¡ info ë¡œê·¸ ì¶œë ¥
- ë™ì¼í•œ TBL_ID ì¤‘ë³µ ì¡´ì¬ ì‹œ warning ë¡œê·¸ ì¶œë ¥
- ë©”íƒ€ ìš”ì²­ ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 5íšŒ ì¬ì‹œë„ (2, 4, 6, 8, 10ì´ˆ ê°„ê²©)
- API ìš”ì²­ ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 10íšŒ ì¬ì‹œë„ (ì ì§„ì  ë°±ì˜¤í”„)
- ì‘ë‹µ ë°ì´í„°ì—ì„œ OBS_VALUEê°€ NaN, '-', '...'ì¸ ê²½ìš° ìë™ í•„í„°ë§
- ëª¨ë“  ì£¼ìš” ì‘ì—…ì€ ë¡œê·¸ë¡œ ê¸°ë¡ (info/error ë¡œê·¸ ë¶„ë¦¬)
- ì˜ˆì™¸ ë°œìƒ ì‹œ traceback í¬í•¨í•œ logger.error ì¶œë ¥ ë° raise ì²˜ë¦¬

------------------------------------------------------------
â–  ì„±ëŠ¥ ìµœì í™” ë° ì„¤ì • ìœ ì—°ì„±
- ë³‘ë ¬ ì²˜ë¦¬ ìˆ˜(max_workers)ë¥¼ kosis_config.inië¡œ ì„¤ì • ê°€ëŠ¥
  - [DEFAULT] ì„¹ì…˜ì—ì„œ `max_workers = 15` ì‹ìœ¼ë¡œ ì§€ì •
  - ì„¤ì •ê°’ì€ ThreadPoolExecutorì˜ ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œì— ì‚¬ìš©ë¨

------------------------------------------------------------
â–  ì¶œë ¥ í…Œì´ë¸”
1. ìˆ˜ì§‘ ë°ì´í„° ì €ì¥: CD_KOSTAT_OPENAPI_VAL
   - ì»¬ëŸ¼: KOSTAT_TBL_ID, TIME_PERIOD, FREQ, ITM_ID, C1~C8, OBS_VALUE ë“±
   - ê³µí†µ ì»¬ëŸ¼ ìë™ ì„¤ì •: Z_REG_*, Z_MOD_*

2. ìˆ˜ì§‘ ì™„ë£Œ ì—¬ë¶€: CD_COLLECT_KOSIS_OPENAPI_YN
   - í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ COMPLETE_YN = 'N'ìœ¼ë¡œ ì´ˆê¸°í™”
   - ì™„ë£Œ í›„ COMPLETE_YN = 'Y'ë¡œ ê°±ì‹ ë¨
   - Z_REG_DTMì€ ìµœì´ˆ ì‹¤í–‰ ì‹œ, Z_MOD_DTMì€ ë§¤ ì‹¤í–‰ ì‹œ ì—…ë°ì´íŠ¸

------------------------------------------------------------
â–  ì‹¤í–‰ ê²°ê³¼ ì˜ˆì‹œ
- kosis_logs/kosis_info_20250521.log : ì •ìƒ ì‹¤í–‰ ë¡œê·¸
- kosis_logs/kosis_error_20250521.log : ì˜¤ë¥˜ ìƒì„¸ ë¡œê·¸
- CD_KOSTAT_OPENAPI_VAL í…Œì´ë¸”ì— ìˆ˜ì§‘ëœ í†µê³„ê°’ ë°˜ì˜
- CD_COLLECT_KOSIS_OPENAPI_YNì— ìˆ˜ì§‘ ìƒíƒœ 'Y'ë¡œ ê¸°ë¡

------------------------------------------------------------
â–  ìˆ˜ì§‘ ê²°ê³¼ ë° ì €ì¥ í†µê³„
- ê° ì‹¤í–‰ì¼ìë³„ URL ìš”ì²­ ìˆ˜ / ì‘ë‹µ ìˆ˜ / ìˆ˜ì§‘ ì„±ê³µë¥ (%) ë¡œê·¸ ì¶œë ¥
- ì‘ë‹µ ì„±ê³µ ì‹œë§ˆë‹¤ ê°œë³„ ì €ì¥ ì²­í¬ ë¡œê·¸ ê¸°ë¡ (start~end index)
- ì €ì¥ ì„±ê³µ ëˆ„ì  ê±´ìˆ˜ëŠ” ìµœì¢…ì ìœ¼ë¡œ info ë¡œê·¸ì— ì¶œë ¥ë¨

------------------------------------------------------------
â–  ì¥ì•  ëŒ€ì‘ ë° ìƒíƒœ í”Œë˜ê·¸ ì²˜ë¦¬
- ë©”íƒ€ ì •ë³´ ë° API ìš”ì²­ ì‹¤íŒ¨ ì‹œ ìµœëŒ€ ì¬ì‹œë„ ë° ë°±ì˜¤í”„ ì ìš©
- ìˆ˜ì§‘ ì‹œì‘ ì „ COMPLETE_YN = 'N'ìœ¼ë¡œ ì´ˆê¸°í™”, ì™„ë£Œ í›„ 'Y'ë¡œ ê°±ì‹ 
- ì˜ˆì™¸ ë°œìƒ ì‹œ traceback í¬í•¨ ë¡œê·¸ ì¶œë ¥ ë° DB rollback ì²˜ë¦¬
"""


import os
import time
import logging
import requests
import configparser
import concurrent.futures
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
from logging.handlers import TimedRotatingFileHandler
import urllib3
import oracledb
import kosis_reader as k_r

urllib3.disable_warnings()

# âœ… ë¡œê±° ì„¤ì • í•¨ìˆ˜
# ë¡œê·¸ íŒŒì¼ì„ info/errorë¡œ ë¶„ë¦¬í•˜ê³ , ë‚ ì§œë³„ë¡œ íŒŒì¼ì„ ìƒì„±í•˜ëŠ” ì„¤ì •ì…ë‹ˆë‹¤.
# - ì½˜ì†” ì¶œë ¥ í•¸ë“¤ëŸ¬
# - info level íŒŒì¼ í•¸ë“¤ëŸ¬
# - error level íŒŒì¼ í•¸ë“¤ëŸ¬
def setup_logger(today: object, log_dir: object) -> object:
    logger = logging.getLogger(f"KOSISLogger_{today}")
    logger.setLevel(logging.DEBUG)
    if not logger.handlers:
        formatter = logging.Formatter('[%(asctime)s] [%(levelname)s] %(message)s', "%Y-%m-%d %H:%M:%S")
        os.makedirs(log_dir, exist_ok=True)
        stream_handler = logging.StreamHandler()
        stream_handler.setFormatter(formatter)
        logger.addHandler(stream_handler)
        info_handler = TimedRotatingFileHandler(
            filename=os.path.join(log_dir, f"kosis_info_{today}.log"),
            when="midnight", interval=1, backupCount=30, encoding="utf-8"
        )
        info_handler.setLevel(logging.INFO)
        info_handler.setFormatter(formatter)
        logger.addHandler(info_handler)
        error_handler = TimedRotatingFileHandler(
            filename=os.path.join(log_dir, f"kosis_error_{today}.log"),
            when="midnight", interval=1, backupCount=14, encoding="utf-8"
        )
        error_handler.setLevel(logging.ERROR)
        error_handler.setFormatter(formatter)
        logger.addHandler(error_handler)
    return logger

# âœ… ê³µí†µ ì»¬ëŸ¼ ì„¸íŒ… í•¨ìˆ˜
# ìˆ˜ì§‘ ë°ì´í„°ì— ê³µí†µ ë“±ë¡/ìˆ˜ì • ì»¬ëŸ¼(Z_*)ì„ ì¶”ê°€í•˜ê³  í˜„ì¬ ì‹œì  ê¸°ì¤€ìœ¼ë¡œ ê°’ì„ ì±„ì›ë‹ˆë‹¤.
# Oracle í…Œì´ë¸”ì˜ ê°ì‚¬ ë¡œê·¸ ëª©ì 
def set_common_cols(df):
    now = datetime.now(ZoneInfo("Asia/Seoul"))
    df_common_cols = pd.DataFrame(columns=[
        'Z_REG_DTM', 'Z_REGR_ID', 'Z_REG_SCR_ID', 'Z_REG_SVC_ID',
        'Z_MOD_DTM', 'Z_MODR_ID', 'Z_MOD_SCR_ID', 'Z_MOD_SVC_ID'
    ])
    df = pd.concat((df, df_common_cols), axis=1, sort=False)
    fill_date = {'Z_REG_DTM': now, 'Z_MOD_DTM': now}
    fill_id = {'Z_REGR_ID': 'bok', 'Z_REG_SCR_ID': 'python', 'Z_REG_SVC_ID': 'python',
               'Z_MODR_ID': 'bok', 'Z_MOD_SCR_ID': 'python', 'Z_MOD_SVC_ID': 'python'}
    pd.set_option('future.no_silent_downcasting', True)
    df = df.fillna(value=fill_date).fillna(value=fill_id).infer_objects(copy=False)
    return df

# âœ… DB ì—°ê²° í•¨ìˆ˜ (ì¬ì‹œë„ í¬í•¨)
# oracledb.SessionPoolì—ì„œ ì»¤ë„¥ì…˜ì„ 3íšŒê¹Œì§€ ì¬ì‹œë„í•˜ì—¬ íšë“í•©ë‹ˆë‹¤.
def get_connection_with_retry(pool, max_retries=3):
    for attempt in range(1, max_retries + 1):
        try:
            return pool.acquire()
        except Exception:
            time.sleep(2)

# âœ… KOSIS API URL ìƒì„±
# ì‹¤í–‰ íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì§‘ URLì„ ìƒì„±í•©ë‹ˆë‹¤.
# KOSIS APIì˜ ì‚¬ìš©ì í†µê³„ ID(userStatsId) ê¸°ë°˜ êµ¬ì„±ì…ë‹ˆë‹¤.
def build_kosis_url(license_key, kosis_id, org_id, tbl_id, url_code, prd_se, prd_de):
    return (
        f"https://kosis.kr/openapi/statisticsData.do?method=getList"
        f"&apiKey={license_key}&format=json&jsonVD=Y&userStatsId={kosis_id}/{org_id}/{tbl_id}/2/2/{url_code}"
        f"&prdSe={prd_se}&startPrdDe={prd_de}&endPrdDe={prd_de}"
    ).replace(' ', '')

# âœ… KOSIS API ìš”ì²­ í•¨ìˆ˜
# URLì— ëŒ€í•´ ìš”ì²­ì„ ë³´ë‚´ê³  JSON ì‘ë‹µì„ ì •ê·œí™”í•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
# - ìµœëŒ€ 10íšŒ ì¬ì‹œë„
# - ì‹¤íŒ¨ì‹œ ë°±ì˜¤í”„(2, 4, ..., 20ì´ˆ) ì ìš©
def fetch_url(url, logger, max_retries=10):
    for attempt in range(1, max_retries + 1):
        try:
            logger.info(f"ğŸŒ ìš”ì²­ ì‹œë„ {attempt}: {url}")
            response = requests.get(url, timeout=(120, 300), verify=False)
            response.raise_for_status()
            logger.info(f"âœ… ìš”ì²­ ì„±ê³µ: {url}")  # âœ… ì„±ê³µ ë¡œê·¸ ì¶”ê°€
            df = pd.json_normalize(response.json())
            df.rename(columns={
                'PRD_DE': 'TIME_PERIOD',
                'PRD_SE': 'FREQ',
                'TBL_ID': 'KOSTAT_TBL_ID',
                'DT': 'OBS_VALUE'
            }, inplace=True)
            return df.reindex(columns=[
                'KOSTAT_TBL_ID', 'TIME_PERIOD', 'FREQ', 'ITM_ID',
                'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'OBS_VALUE'
            ])
        except Exception as e:
            logger.warning(f"âš ï¸ ìš”ì²­ ì‹¤íŒ¨ ({attempt}): {url} - {e}")
            time.sleep(attempt * 2)
    logger.error(f"âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {url}")
    return None

# âœ… ìˆ˜ì§‘ ìƒíƒœ í”Œë˜ê·¸ ì‚½ì…/ê°±ì‹  í•¨ìˆ˜
# ìƒíƒœ í…Œì´ë¸”(CD_COLLECT_KOSIS_OPENAPI_YN)ì— ìˆ˜ì§‘ ì—¬ë¶€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
# - is_init=Trueì¼ ê²½ìš°: DELETE í›„ INSERT (ì´ˆê¸°í™”)
# - is_init=Falseì¼ ê²½ìš°: UPDATE only
def upsert_complete_flag(connection, today, complete_yn, is_init=False, logger=None):
    now = datetime.now(ZoneInfo("Asia/Seoul"))

    if is_init:
        # âœ… ìµœì´ˆ 1íšŒ ì´ˆê¸°í™”: DELETE í›„ INSERT
        delete_sql = "DELETE FROM CD_COLLECT_KOSIS_OPENAPI_YN WHERE COLLECT_DATE = :1"
        insert_sql = """
            INSERT INTO CD_COLLECT_KOSIS_OPENAPI_YN (
                COLLECT_DATE, COMPLETE_YN,
                Z_REG_DTM, Z_REGR_ID, Z_REG_SCR_ID, Z_REG_SVC_ID,
                Z_MOD_DTM, Z_MODR_ID, Z_MOD_SCR_ID, Z_MOD_SVC_ID
            ) VALUES (
                :1, :2,
                :3, :4, :5, :6,
                :7, :8, :9, :10
            )
        """
        params = [
            today, complete_yn,
            now, 'bok', 'python', 'python',
            now, 'bok', 'python', 'python'
        ]

        try:
            with connection.cursor() as cursor:
                cursor.execute(delete_sql, [today])
                logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ COLLECT_DATE = {today} ì‚­ì œ ì™„ë£Œ")

                cursor.execute(insert_sql, params)
                logger.info(f"ğŸ†• COLLECT_DATE = {today}, COMPLETE_YN = '{complete_yn}' ì‹ ê·œ ì‚½ì… ì™„ë£Œ")

                connection.commit()
                logger and logger.info("âœ… íŠ¸ëœì­ì…˜ ì»¤ë°‹ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ìƒíƒœ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
            raise
            # pass
    else:
        # âœ… ì´í›„ëŠ” UPDATEë§Œ ìˆ˜í–‰
        update_sql = """
            UPDATE CD_COLLECT_KOSIS_OPENAPI_YN
            SET COMPLETE_YN = :1,
                Z_MOD_DTM = :2
            WHERE COLLECT_DATE = :3
        """
        params = [
            complete_yn, now, today
        ]

        try:
            with connection.cursor() as cursor:
                cursor.execute(update_sql, params)
                logger.info(f"ğŸ”„ COMPLETE_YN = '{complete_yn}' ì—…ë°ì´íŠ¸ ì™„ë£Œ (ì—…ë°ì´íŠ¸ í–‰ ìˆ˜: {cursor.rowcount})")
                if cursor.rowcount == 0:
                    logger.warning(f"âš ï¸ UPDATE ì‹¤íŒ¨: COLLECT_DATE={today} ëŒ€ìƒ í–‰ ì—†ìŒ")
                connection.commit()
        except Exception as e:
            logger and logger.error(f"âŒ ìƒíƒœ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
            raise

# âœ… KOSIS ë°ì´í„° Oracle DB Insert í•¨ìˆ˜
# ë°ì´í„°í”„ë ˆì„ì„ 1000ê±´ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ CD_KOSTAT_OPENAPI_VAL í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.
# - í¬ì§€ì…”ë„ ë°”ì¸ë”© ë°©ì‹ (:1 ~ :21)
# - setinputsizes()ëŠ” ì œê±°ë˜ì–´ì•¼ í•¨ (í˜¼ìš© ì‹œ ì˜¤ë¥˜ ë°œìƒ)
def insert_kosis_data(df_final: pd.DataFrame, connection, logger):
    """
    Oracle DBì— KOSIS ë°ì´í„°ë¥¼ bulk insert (ìµœì í™”ëœ array binding ì‚¬ìš©)
    """

    insert_sql = """
        INSERT INTO CD_KOSTAT_OPENAPI_VAL (
            KOSTAT_TBL_ID, TIME_PERIOD, FREQ, ITM_ID,
            C1, C2, C3, C4, C5, C6, C7, C8, OBS_VALUE,
            Z_REG_DTM, Z_REGR_ID, Z_REG_SCR_ID, Z_REG_SVC_ID,
            Z_MOD_DTM, Z_MODR_ID, Z_MOD_SCR_ID, Z_MOD_SVC_ID
        ) VALUES (
            :1, :2, :3, :4, :5, :6, :7, :8, :9, :10, :11, :12,
            :13, :14, :15, :16, :17, :18, :19, :20, :21
        )
    """

    chunk_size = 1000
    cols = ['KOSTAT_TBL_ID', 'TIME_PERIOD', 'FREQ', 'ITM_ID',
            'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'OBS_VALUE',
            'Z_REG_DTM', 'Z_REGR_ID', 'Z_REG_SCR_ID', 'Z_REG_SVC_ID',
            'Z_MOD_DTM', 'Z_MODR_ID', 'Z_MOD_SCR_ID', 'Z_MOD_SVC_ID']

    saved_count = 0  # âœ… ì´ ì €ì¥ ê±´ìˆ˜ ëˆ„ì  ë³€ìˆ˜
    with connection.cursor() as cursor:
        for start in range(0, len(df_final), chunk_size):
            chunk_df = df_final.iloc[start:start + chunk_size][cols]
            rows = [tuple(row) for row in chunk_df.itertuples(index=False, name=None)]
            try:
                cursor.executemany(insert_sql, rows)
                connection.commit()
                saved_count += len(chunk_df)  # âœ… ì €ì¥ ê±´ìˆ˜ ëˆ„ì 
                logger.info(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: rows {start} ~ {start + len(chunk_df) - 1}")
            except Exception as e:
                logger.error(f"âŒ Insert ì‹¤íŒ¨ (rows {start} ~ {start + len(chunk_df) - 1}): {e}", exc_info=True)
                connection.rollback()
        logger.info(f"âœ… ì´ ì €ì¥ ê±´ìˆ˜: {saved_count:,} rows")

# âœ… ë©”ì¸ ìˆ˜ì§‘ ì‹¤í–‰ í•¨ìˆ˜
# 1. ìˆ˜ì§‘ ëŒ€ìƒ í†µê³„í‘œ ëª©ë¡ ì¡°íšŒ
# 2. ê° í†µê³„í‘œì— ëŒ€í•´ ìë£Œê°±ì‹ ì¼ ë©”íƒ€ ìš”ì²­
# 3. ê°±ì‹ ì¼ ê¸°ì¤€ í•„í„°ë§ (execute_date - days_back ~ execute_date)
# 4. ìˆ˜ì§‘ URL ìƒì„± ë° ë³‘ë ¬ ìš”ì²­
# 5. ìˆ˜ì§‘ëœ ê²°ê³¼ ì •ì œ í›„ Oracle ì €ì¥
# 6. ì„±ê³µë¥  í†µê³„ ë° COMPLETE_YN ìƒíƒœ ê°±ì‹ 
def run_kosis_process_logging(execute_dates, config, today, days_back, pool, logger, max_workers):
    start_time = time.time()
    all_data = []
    date_stats = []  # âœ… ë‚ ì§œë³„ ìˆ˜ì§‘ í†µê³„ ì €ì¥ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
    failed_dates = []  # ğŸ’¥ DB ì €ì¥ ì‹¤íŒ¨ ì¼ì ì €ì¥ìš©
    logger.info(f"âœ… KOSIS ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ | ëŒ€ìƒì¼ì: {execute_dates}")

    connection = get_connection_with_retry(pool)
    logger.info("ğŸ”— Oracle DB ì—°ê²° ì„±ê³µ")

    license_key = config.get("KOSIS", "license_key")
    kosis_id = config.get("KOSIS", "kosis_id")

    for execute_date in execute_dates:
        logger.info(f"ğŸŸ¡ ìˆ˜ì§‘ ì‹œì‘: {execute_date}")

        cursor = connection.cursor()

        # kosis_config.iniì—ì„œ í•„í„°ìš© TBL_ID ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
        tbl_id_raw = config.get("DEFAULT", "tbl_id", fallback="").strip()
        tbl_id = [tbl.strip() for tbl in tbl_id_raw.split(',') if tbl.strip()]

        # SQL ì¡°ê±´ì ˆ ì¡°ë¦½
        if tbl_id:
            # ë°”ì¸ë”© ê°€ëŠ¥í•œ IN ì¡°ê±´ ìƒì„± (:1, :2, ...)
            placeholders = ','.join([f':{i + 1}' for i in range(len(tbl_id))])
            sql = f"""
                SELECT ORG_ID, TBL_ID, URL
                FROM CD_KOSIS_REQ_MPP_P
                WHERE URL IS NOT NULL AND TBL_ID IN ({placeholders})
            """
            cursor.execute(sql, tbl_id)
            logger.info(f"ğŸ” TBL_ID í•„í„° ì ìš©ë¨: {tbl_id}")
        else:
            sql = "SELECT ORG_ID, TBL_ID, URL FROM CD_KOSIS_REQ_MPP_P WHERE URL IS NOT NULL"
            cursor.execute(sql)

        # ê²°ê³¼ â†’ DataFrame
        df_org_tbl = pd.DataFrame(cursor.fetchall(), columns=[col[0] for col in cursor.description])

        dup_check = df_org_tbl.duplicated(subset=['TBL_ID'], keep=False)
        if dup_check.any():
            dup_list = df_org_tbl[dup_check]['TBL_ID'].drop_duplicates().tolist()
            logger.warning(f"âš ï¸ ì¤‘ë³µëœ TBL_ID ì¡´ì¬ ({len(dup_list)}ê°œ): {dup_list}")

        # âœ… ì´í›„ ì‹¤ì œ ì²˜ë¦¬ìš©ìœ¼ë¡œëŠ” ì™„ì „ ì¤‘ë³µ ì œê±°
        df_org_tbl = df_org_tbl.drop_duplicates(subset=['TBL_ID', 'ORG_ID', 'URL'])

        cursor.close()

        logger.info(f"ğŸ“‹ ìˆ˜ì§‘ ëŒ€ìƒ í†µê³„í‘œ ìˆ˜: {len(df_org_tbl)}ê°œ")
        tbl_ids = df_org_tbl['TBL_ID'].tolist()
        logger.info("ğŸ“„ ìˆ˜ì§‘ ëŒ€ìƒ ëª©ë¡:")
        for i, tbl_id in enumerate(tbl_ids, 1):
            logger.info(f"{i}. {tbl_id}")

        api = k_r.Kosis(license_key)
        results = []

        for idx, row in df_org_tbl.iterrows():
            logger.debug(f"ğŸ” ë©”íƒ€ì •ë³´ ìš”ì²­ [{idx + 1}/{len(df_org_tbl)}]: ORG_ID={row['ORG_ID']} / TBL_ID={row['TBL_ID']}")
            for attempt in range(1, 6):
                try:
                    meta = api.get_data(
                        service_name='í†µê³„í‘œì„¤ëª…',
                        detail_service_name='ìë£Œê°±ì‹ ì¼',
                        orgId=row['ORG_ID'],
                        tblId=row['TBL_ID']
                    )
                    meta['org_id'], meta['tbl_id'], meta['col_url'] = row['ORG_ID'], row['TBL_ID'], row['URL']
                    results.append(meta)
                    logger.debug(f"âœ… ë©”íƒ€ì •ë³´ ìš”ì²­ ì„±ê³µ [{idx + 1}/{len(df_org_tbl)}]")
                    break
                except Exception as e:
                    logger.warning(f"âš ï¸ ë©”íƒ€ ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {attempt}) [{idx + 1}/{len(df_org_tbl)}]: {e}")
                    time.sleep(attempt * 2)

        if not results:
            logger.warning(f"âŒ ë©”íƒ€ ì •ë³´ ì—†ìŒ: {execute_date}")
            continue


        df_meta = pd.concat(results, ignore_index=True)

        if df_meta.empty:
            logger.warning(f"âš ï¸ í•„í„°ë§ í›„ ë°ì´í„° ì—†ìŒ: {execute_date}")
            continue

        # ë‚ ì§œ í˜•ì‹ ë³€í™˜
        exec_date_obj = datetime.strptime(execute_date, "%Y-%m-%d")

        # ğŸ’¡ ì‹¤í–‰ì¼ ê¸°ì¤€ìœ¼ë¡œ days_backì¼ ì „ë¶€í„° í¬í•¨ (ì˜ˆ: 2025-05-20 ê¸°ì¤€ 6ì¼ ì „ â†’ 2025-05-14 í¬í•¨)
        start_date = (exec_date_obj - timedelta(days=days_back)).strftime("%Y-%m-%d")  # ì¼ì£¼ì¼ ì „
        end_date = execute_date  # ì‹¤í–‰ì¼ìê¹Œì§€ í¬í•¨

        # í•„í„°ë§ ì¡°ê±´ ë³€ê²½ (ìë£Œê°±ì‹ ì¼ì´ ë¬¸ìì—´ë¡œ ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
        # âœ… ìë£Œê°±ì‹ ì¼ì´ ì§€ì •ëœ ë²”ìœ„ ë‚´ì¸ í†µê³„í‘œë§Œ í•„í„°ë§
        df_meta = df_meta[
            (df_meta['ìë£Œê°±ì‹ ì¼'] >= start_date) &
            (df_meta['ìë£Œê°±ì‹ ì¼'] <= end_date)
            ]

        logger.info(f"ğŸ“Œ ê°±ì‹ ì¼ì ì¼ì¹˜ í†µê³„í‘œ ìˆ˜: {len(df_meta)}")
        # print(df_meta)

        freq_map = {"ì›”": "M", "ë°˜ê¸°": "S", "ë…„": "Y", "ë¶„ê¸°": "Q"}
        df_meta["ìˆ˜ë¡ì£¼ê¸°"] = df_meta["ìˆ˜ë¡ì£¼ê¸°"].map(freq_map)

        url_list = [
            build_kosis_url(license_key, kosis_id, row['org_id'], row['tbl_id'],
                            row['col_url'], row['ìˆ˜ë¡ì£¼ê¸°'], row['ìˆ˜ë¡ì‹œì '])
            for _, row in df_meta.iterrows()
        ]
        url_list = list(set(filter(None, url_list)))
        logger.info(f"ğŸŒ ë°ì´í„° ìˆ˜ì§‘ URL ìˆ˜: {len(url_list)}")

        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_url = {executor.submit(fetch_url, url, logger): url for url in url_list}
            # execute_date ë‹¨ìœ„ë¡œ ì²˜ë¦¬ & DB ì¦‰ì‹œ ì €ì¥
            day_data = []
            for future in concurrent.futures.as_completed(future_to_url):
                df = future.result()
                if df is not None:
                    day_data.append(df)

            if day_data:
                df_final = pd.concat(day_data, ignore_index=True)
                df_final = df_final.replace({np.nan: None})
                df_final = df_final[df_final['OBS_VALUE'].notna()]
                df_final = df_final[~df_final['OBS_VALUE'].isin(['-', '...'])]
                df_final['OBS_VALUE'] = pd.to_numeric(df_final['OBS_VALUE'], errors='coerce')
                df_final = df_final.dropna(subset=['KOSTAT_TBL_ID'])

                df_final = set_common_cols(df_final)
                logger.info(f"ğŸ“¦ [{execute_date}] ì •ì œëœ ë°ì´í„° ìˆ˜: {len(df_final)}")

                insert_kosis_data(df_final, connection, logger)
            else:
                logger.warning(f"âš ï¸ ìˆ˜ì§‘ ë°ì´í„° ì—†ìŒ: {execute_date}")

        # âœ… ë‚ ì§œë³„ í†µê³„ ì €ì¥
        date_stats.append({
            "date": execute_date,
            "url_count": len(url_list),
            "success_count": len(day_data)
        })

        # âœ… ëŒ€ì²´: ìˆ˜ì§‘ì´ ì „í˜€ ì—†ì„ ë•Œ ê²½ê³ ë§Œ ë‚¨ê¹€
        if not date_stats:
            logger.warning("âš ï¸ ì „ì²´ ê¸°ê°„ ë™ì•ˆ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. DB ì €ì¥ ë° ìƒíƒœ í”Œë˜ê·¸ ìŠ¤í‚µë©ë‹ˆë‹¤.")

    elapsed = round(time.time() - start_time, 2)
    minutes = int(elapsed // 60)
    seconds = round(elapsed % 60, 2)

    logger.info(f"ğŸ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ | ì´ ì†Œìš”ì‹œê°„: {minutes}ë¶„ {seconds}ì´ˆ")

    # âœ… ë‚ ì§œë³„ ìˆ˜ì§‘ í†µê³„ ìš”ì•½ ì¶œë ¥
    if date_stats:
        logger.info("ğŸ“Š ë‚ ì§œë³„ ìˆ˜ì§‘ ì„±ê³µë¥  í†µê³„")
        for stat in date_stats:
            rate = round(stat['success_count'] / stat['url_count'] * 100, 2) if stat['url_count'] else 0.0
            logger.info(
                f"ğŸ“… {stat['date']} | URL ìˆ˜: {stat['url_count']} | ì„±ê³µ ìˆ˜: {stat['success_count']} | ì„±ê³µë¥ : {rate:.2f}%")

    upsert_complete_flag(connection, today, 'Y', is_init=False, logger=logger)
    logger.info("ğŸ“ ìƒíƒœ í”Œë˜ê·¸ (Y) ì €ì¥ ì™„ë£Œ")
    connection.close()
    logger.info("ğŸ”Œ Oracle DB ì—°ê²° ì¢…ë£Œ")

# âœ… main í•¨ìˆ˜
# kosis_config.ini ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°, ë‚ ì§œ ê³„ì‚°, ë¡œê±° ì„¤ì •, DB pool ìƒì„±
# ì´ˆê¸° COMPLETE_YN = 'N' ì„¤ì • í›„ ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
def main():

    config = configparser.ConfigParser()
    config.read("kosis_config/config.ini", encoding="utf-8")

    execute_raw = config.get("DEFAULT", "execute_date", fallback="")
    base_date = datetime.strptime(execute_raw.strip(), "%Y-%m-%d") if execute_raw else datetime.now()

    today = datetime.now().strftime("%Y%m%d")  # YYYYMMDD í˜•ì‹
    log_dir = config.get("DEFAULT", "log_dir")

    max_workers_str = config.get("DEFAULT", "max_workers", fallback="10").strip()
    max_workers = int(max_workers_str) if max_workers_str else 15

    # âœ… ë¡œê±° ë¨¼ì € ì„¸íŒ…í•´ì•¼ ì´í›„ logging ê°€ëŠ¥
    logger = setup_logger(today, log_dir)

    execute_dates = [
        (base_date - timedelta(days=offset)).strftime("%Y-%m-%d")
        for offset in reversed(range(1))
    ]

    # ğŸ’¡ ì‹¤í–‰ì¼ ê¸°ì¤€ìœ¼ë¡œ days_backì¼ ì „ë¶€í„° í¬í•¨ (ì˜ˆ: 2025-05-20 ê¸°ì¤€ 6ì¼ ì „ â†’ 2025-05-14 í¬í•¨)
    days_back_str = config.get("DEFAULT", "days_back", fallback="6").strip()
    days_back = int(days_back_str) if days_back_str else 6

    # âœ… Oracle DB ì—°ê²° (ìµœì´ˆ 1íšŒ)
    pool = oracledb.SessionPool(
        user=config.get("DB", "user"),
        password=config.get("DB", "password"),
        dsn=config.get("DB", "dsn"),
        min=config.getint("DB", "min"),
        max=config.getint("DB", "max"),
        increment=config.getint("DB", "increment"),
        encoding=config.get("DB", "encoding")
    )
    connection = get_connection_with_retry(pool)

    # âœ… ìµœì´ˆ 1íšŒ ìƒíƒœ ì´ˆê¸°í™” (COMPLETE_YN = 'N', Z_REG_DTM í¬í•¨)
    upsert_complete_flag(connection, today, 'N', is_init=True, logger=logger)
    logger.info("ğŸ“ ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ (COMPLETE_YN = 'N', Z_REG_DTM ìµœì‹ í™”)")
    connection.close()

    run_kosis_process_logging(execute_dates, config, today, days_back, pool, logger, max_workers)


if __name__ == "__main__":
    main()
